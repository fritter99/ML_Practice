{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_DynamicProgram.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGQHtePDX6MQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tcq--EM1S4zx",
        "colab_type": "text"
      },
      "source": [
        "## Value Iteration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXMontTjXi3k",
        "colab_type": "text"
      },
      "source": [
        "### 初始化环境"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHkdePu9XTdW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "environment = gym.make('FrozenLake-v0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysMPd8qUh_5f",
        "colab_type": "code",
        "outputId": "87353095-feac-459e-8772-87e13764a0c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "# 打印环境\n",
        "environment.render()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgM6DFbHAmbn",
        "colab_type": "code",
        "outputId": "0d39b390-da62-4259-93f0-fe15e7dd25b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# 查看从一个state到new state的概率\n",
        "# 从state=6开始(也就是从起点开始), 进行action=1(向下走), 会有可能向左或右走.\n",
        "# LEFT = 0, DOWN = 1, RIGHT = 2, UP = 3\n",
        "\n",
        "state = 6\n",
        "action = 1\n",
        "environment.P[state][action]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.3333333333333333, 5, 0.0, True),\n",
              " (0.3333333333333333, 10, 0.0, False),\n",
              " (0.3333333333333333, 7, 0.0, True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cztRXVArYcb_",
        "colab_type": "text"
      },
      "source": [
        "### Value Iteration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86RDHYThFb72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_step_lookahead(environment, state, V, discount_factor):\n",
        "    # Create a vector of dimensionality same as the number of actions\n",
        "    action_values = np.zeros(environment.nA)\n",
        "\n",
        "    for action in range(environment.nA):\n",
        "        # 采取同一个action, 达到不同的state\n",
        "        for probability, next_state, reward, terminated in environment.P[state][action]:\n",
        "            if reward == 0:\n",
        "                reward = -1\n",
        "            elif reward == 1:\n",
        "                reward = 10\n",
        "            action_values[action] += probability * (reward + discount_factor * V[next_state])\n",
        "    return action_values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KePFUA2pYt1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def value_iteration(environment, discount_factor=1.0, max_iterations=1e9, theta=1e-9):\n",
        "    # delta用来判断两次更新之间V的变化\n",
        "    delta = 0\n",
        "    # 初始化value\n",
        "    V = np.zeros(environment.nS)\n",
        "    # Store the number of policies evaluated\n",
        "    evaluated_policies = 1\n",
        "\t\n",
        "    for i in range(int(max_iterations)):\t\n",
        "        # 每一次迭代对所有的state进行更新\n",
        "        for state in range(environment.nS):\n",
        "            # 计算这个从这个state出发的每一个action最后可以获得的收益\n",
        "            action_values = one_step_lookahead(environment, state, V, discount_factor)\n",
        "            # 获得最好的动作\n",
        "            best_value = np.max(action_values)\n",
        "            # 保存一个更新前后最大的差距\n",
        "            delta = max(delta, abs(V[state] - best_value))\n",
        "            # 更新V\n",
        "            V[state] = best_value\n",
        "\t\t\n",
        "        evaluated_policies += 1\n",
        "        if (i+1) % 100 == 0:\n",
        "            print('='*10)\n",
        "            print('Steps:{}'.format(evaluated_policies))\n",
        "            print(V.reshape(4,4))\n",
        "\n",
        "        # 是否要早停止\n",
        "        if delta < theta:\n",
        "            print('Early Stop. Steps:{}'.format(evaluated_policies))\n",
        "            return V\n",
        "\n",
        "    print('Steps:{}'.format(evaluated_policies))\n",
        "    return V"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joepgDp4H5UJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_policy(environment, V, discount_factor):\n",
        "    \"\"\"给定V, 生成对应的policy\n",
        "    \"\"\"\n",
        "    policy = np.zeros((environment.nS, environment.nA))\n",
        "    # 找出每一个state的最佳步骤\n",
        "    for state in range(environment.nS):\n",
        "        action_values = one_step_lookahead(environment, state, V, discount_factor)\n",
        "        # 获得收益最大的那个action\n",
        "        best_action = np.argmax(action_values)\n",
        "        # 更新policy\n",
        "        policy[state][best_action] = 1\n",
        "    \n",
        "    return policy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71qVupg1Y1ku",
        "colab_type": "code",
        "outputId": "ca0a6b5f-9a23-46e5-ec29-a3aefa3393f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        }
      },
      "source": [
        "V = value_iteration(environment=environment, discount_factor=0.9, max_iterations=500, theta=1e-1)\n",
        "print(V.reshape(4,4))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==========\n",
            "Steps:101\n",
            "[[-9.24207816 -9.32430612 -9.18133513 -9.38597772]\n",
            " [-8.98947819 -9.99973439 -8.765515   -9.99973439]\n",
            " [-8.40006607 -7.27737513 -6.70402963 -9.99973439]\n",
            " [-9.99973439 -5.82052745 -2.97056562 -9.99973439]]\n",
            "==========\n",
            "Steps:201\n",
            "[[-9.24220004 -9.32443971 -9.18149261 -9.38611946]\n",
            " [-8.98960006 -9.99999999 -8.76570972 -9.99999999]\n",
            " [-8.40020009 -7.2775335  -6.70420648 -9.99999999]\n",
            " [-9.99999999 -5.82070508 -2.97077837 -9.99999999]]\n",
            "==========\n",
            "Steps:301\n",
            "[[ -9.24220005  -9.32443971  -9.18149262  -9.38611946]\n",
            " [ -8.98960006 -10.          -8.76570973 -10.        ]\n",
            " [ -8.4002001   -7.2775335   -6.70420648 -10.        ]\n",
            " [-10.          -5.82070509  -2.97077837 -10.        ]]\n",
            "==========\n",
            "Steps:401\n",
            "[[ -9.24220005  -9.32443971  -9.18149262  -9.38611946]\n",
            " [ -8.98960006 -10.          -8.76570973 -10.        ]\n",
            " [ -8.4002001   -7.2775335   -6.70420648 -10.        ]\n",
            " [-10.          -5.82070509  -2.97077837 -10.        ]]\n",
            "==========\n",
            "Steps:501\n",
            "[[ -9.24220005  -9.32443971  -9.18149262  -9.38611946]\n",
            " [ -8.98960006 -10.          -8.76570973 -10.        ]\n",
            " [ -8.4002001   -7.2775335   -6.70420648 -10.        ]\n",
            " [-10.          -5.82070509  -2.97077837 -10.        ]]\n",
            "Steps:501\n",
            "[[ -9.24220005  -9.32443971  -9.18149262  -9.38611946]\n",
            " [ -8.98960006 -10.          -8.76570973 -10.        ]\n",
            " [ -8.4002001   -7.2775335   -6.70420648 -10.        ]\n",
            " [-10.          -5.82070509  -2.97077837 -10.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8QAJRaWZmf0",
        "colab_type": "code",
        "outputId": "70086f84-aa4f-4885-e0fd-c14a365f6646",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "policy= generate_policy(environment, V, discount_factor=0.9)\n",
        "print(policy)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY20vmNwmTDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}